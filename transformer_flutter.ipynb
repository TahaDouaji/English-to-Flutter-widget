{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCEmvQRNy08n"
      },
      "source": [
        "# Transformer model for converting English sentences into Flutter UI widgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL8eiwoIKHAY"
      },
      "source": [
        "In these lines of code, we'll train **Seq2seq Transformer** model to convert natural English sentences into Flutter UI widget code.\n",
        "\n",
        "Our generated dataset has around 175000 English sentences and around 175000 Flutter widget code\n",
        "\n",
        "The goal of this experiment is totally for research purposes, We're not going to support all Flutter widgets for the current phase and also we are using some custom Widget instead of the regular widget to make things easier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaquklxUshV7",
        "outputId": "12da2fe4-f614-4139-af87-02b7a96040e0"
      },
      "source": [
        "!git clone https://github.com/TahaDouaji/English-to-Flutter-widget.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'English-to-Flutter-widget'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 35 (delta 15), reused 25 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (35/35), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6ob-B1Bsls7",
        "outputId": "1af05fb2-bc43-4051-ffb1-6d0ccfa4664d"
      },
      "source": [
        "%cd English-to-Flutter-widget/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/English-to-Flutter-widget\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlDML1sGRA0H"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import spacy\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchtext.legacy.datasets import Multi30k\n",
        "from torchtext.legacy.data import Field, BucketIterator\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfCHrN2ULCkx"
      },
      "source": [
        "# Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPXXqBITuoqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d21cf5e-8e3a-46c5-93d0-228d9c903354"
      },
      "source": [
        "import json\n",
        "dataset = []\n",
        "with open(\"data_set.json\", 'r') as file:\n",
        "    data_json = file.read()\n",
        "\n",
        "    array_of_obj = json.loads(data_json)\n",
        "    for it in array_of_obj:\n",
        "        dataset.append(it)\n",
        "\n",
        "print(len(dataset))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "175632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QS_ojMVutuO"
      },
      "source": [
        "from random import shuffle\n",
        "shuffle(dataset)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERkU1ab_LWBH",
        "outputId": "d292c56a-9960-4eb4-84c8-e48eb151ccb2"
      },
      "source": [
        "dataset[:10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'sentence': 'Row parent of add a string with font Color Colors.value and fontSize value and value and textAlign TextAlign.value',\n",
              "  'widget': 'Row( children:[ Text ( fontColor: Colors.value, fontSize: value, value, textAlign: TextAlign.value )  ],)'},\n",
              " {'sentence': 'build a label with value and text Align TextAlign.value and font Size value and fontColor Colors.value',\n",
              "  'widget': 'Text ( value, textAlign: TextAlign.value, fontSize: value, fontColor: Colors.value ) '},\n",
              " {'sentence': 'write a title has text Align TextAlign.value and fontSize value and fontColor Colors.value and value inside a Row',\n",
              "  'widget': 'Row( children:[ Text ( textAlign: TextAlign.value, fontSize: value, fontColor: Colors.value, value )  ],)'},\n",
              " {'sentence': 'write a text with text Align TextAlign.value and value and fontSize value and font Color Colors.value',\n",
              "  'widget': 'Text ( textAlign: TextAlign.value, value, fontSize: value, fontColor: Colors.value ) '},\n",
              " {'sentence': 'Column parent of create a container has width value and height value',\n",
              "  'widget': 'Column( children:[ Container ( width: value, height: value )  ],)'},\n",
              " {'sentence': 'Center parent of write a string has value and fontSize value and textAlign TextAlign.value and font Color Colors.value',\n",
              "  'widget': 'Center( child: Text ( value, fontSize: value, textAlign: TextAlign.value, fontColor: Colors.value )  )'},\n",
              " {'sentence': 'build a content with color Colors.value and fontSize value and value and textAlign TextAlign.value',\n",
              "  'widget': 'Text ( fontColor: Colors.value, fontSize: value, value, textAlign: TextAlign.value ) '},\n",
              " {'sentence': 'create a box with height value and padding EdgeInsets.all(value) and color Colors.value and width value inside a Column',\n",
              "  'widget': 'Column( children:[ Container ( height: value, padding: EdgeInsets.all(value), color: Colors.value, width: value )  ],)'},\n",
              " {'sentence': 'add a text with value and font Color Colors.value and fontSize value and textAlign TextAlign.value inside a Column',\n",
              "  'widget': 'Column( children:[ Text ( value, fontColor: Colors.value, fontSize: value, textAlign: TextAlign.value )  ],)'},\n",
              " {'sentence': 'Center parent of build a content with value and fontSize value and textAlign TextAlign.value and fontColor Colors.value',\n",
              "  'widget': 'Center( child: Text ( value, fontSize: value, textAlign: TextAlign.value, fontColor: Colors.value )  )'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imf9rcPsMbMW"
      },
      "source": [
        "# Tokenizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPn_KZY-MdbL"
      },
      "source": [
        "For English sentences, we're going to use Spacy as our input Tokenizer\n",
        "For the output Tokenizer, we'll build our own custom tokenizer. We didn't find a suitable tokenizer for Dart/Flutter so we'll be using Python's default[tokenize](https://docs.python.org/3/library/tokenize.html) for now and it will be changed later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkjlW18whxs9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da380a7f-328c-4ec9-9126-494c08484026"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.2.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.6.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtQJ0XqCX7_D"
      },
      "source": [
        "from tokenize import tokenize, untokenize\n",
        "import io\n",
        "\n",
        "\n",
        "def tokenize_flutter_code(str_code):\n",
        "    fluttere_tokens = list(tokenize(io.BytesIO(str_code.encode('utf-8')).readline))\n",
        "    return [it.string for it in fluttere_tokens if len(it.string) > 0]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqOMP67SQUW4",
        "outputId": "4c715158-dfd8-4e36-f987-e6d8eda23750"
      },
      "source": [
        "tokenize_flutter_code(\"Container(color:Color.red)\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['utf-8', 'Container', '(', 'color', ':', 'Color', '.', 'red', ')']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqUgeel-wzNu"
      },
      "source": [
        "from torchtext.legacy import data\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import time"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wl5-dG4thb-"
      },
      "source": [
        "Input = Field(tokenize='spacy',\n",
        "            init_token='<sos>', \n",
        "            eos_token='<eos>', \n",
        "            lower=True)\n",
        "\n",
        "Output = Field(tokenize = tokenize_flutter_code,\n",
        "                      init_token='<sos>', \n",
        "                    eos_token='<eos>', \n",
        "                    lower=False)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR6Idc0fuZgV"
      },
      "source": [
        "fields = [('Input', Input),('Output', Output)]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usWMgI3sRmvt"
      },
      "source": [
        "# Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVzqy5o3u95Z"
      },
      "source": [
        "dataset_df = pd.DataFrame(dataset)\n",
        "\n",
        "\n",
        "np.random.seed(0)\n",
        "msk = np.random.rand(len(dataset_df)) < 0.85\n",
        "\n",
        "\n",
        "train_df = dataset_df[msk]\n",
        "val_df = dataset_df[~msk]\n",
        "\n",
        "val_msk = np.random.rand(len(pd.DataFrame(train_df))) < 0.85\n",
        "test_df = train_df[~val_msk]\n",
        "train_df = train_df[val_msk]\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "train_example = []\n",
        "val_example = []\n",
        "test_example = []\n",
        "\n",
        "train_expansion_factor = 1\n",
        "for j in range(train_expansion_factor):\n",
        "  for i in range(train_df.shape[0]):\n",
        "      try:\n",
        "          ex = data.Example.fromlist([train_df.sentence[i], train_df.widget[i]], fields)\n",
        "          train_example.append(ex)\n",
        "      except:\n",
        "          pass\n",
        "\n",
        "for i in range(val_df.shape[0]):\n",
        "    try:\n",
        "        ex = data.Example.fromlist([val_df.sentence[i], val_df.widget[i]], fields)\n",
        "        val_example.append(ex)\n",
        "    except:\n",
        "        pass  \n",
        "\n",
        "for i in range(test_df.shape[0]):\n",
        "    try:\n",
        "        ex = data.Example.fromlist([test_df.sentence[i], test_df.widget[i]], fields)\n",
        "        test_example.append(ex)\n",
        "    except:\n",
        "        pass       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY5aBm0FIDU9"
      },
      "source": [
        "len(train_example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLzv4ZoiRu9X"
      },
      "source": [
        "# Creating vocabulary using torchtext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzspadWERec_"
      },
      "source": [
        "train_data = data.Dataset(train_example, fields)\n",
        "valid_data =  data.Dataset(val_example, fields)\n",
        "test_data =  data.Dataset(test_example, fields)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zPabvACzF-R"
      },
      "source": [
        "Input.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "Output.build_vocab(train_data, max_size=10000, min_freq=2)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB39Q9iSR8Cf"
      },
      "source": [
        "# Transformer class model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9VVFtIjRI_I"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size,\n",
        "        src_vocab_size,\n",
        "        trg_vocab_size,\n",
        "        src_pad_idx,\n",
        "        num_heads,\n",
        "        num_encoder_layers,\n",
        "        num_decoder_layers,\n",
        "        forward_expansion,\n",
        "        dropout,\n",
        "        max_len,\n",
        "        device,\n",
        "    ):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
        "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
        "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
        "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n",
        "\n",
        "        self.device = device\n",
        "        self.transformer = nn.Transformer(\n",
        "            embedding_size,\n",
        "            num_heads,\n",
        "            num_encoder_layers,\n",
        "            num_decoder_layers,\n",
        "            forward_expansion,\n",
        "            dropout,\n",
        "        )\n",
        "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
        "\n",
        "        # (N, src_len)\n",
        "        return src_mask.to(self.device)\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        src_seq_length, N = src.shape\n",
        "        trg_seq_length, N = trg.shape\n",
        "\n",
        "        src_positions = (\n",
        "            torch.arange(0, src_seq_length)\n",
        "            .unsqueeze(1)\n",
        "            .expand(src_seq_length, N)\n",
        "            .to(self.device)\n",
        "        )\n",
        "\n",
        "        trg_positions = (\n",
        "            torch.arange(0, trg_seq_length)\n",
        "            .unsqueeze(1)\n",
        "            .expand(trg_seq_length, N)\n",
        "            .to(self.device)\n",
        "        )\n",
        "\n",
        "        embed_src = self.dropout(\n",
        "            (self.src_word_embedding(src) + self.src_position_embedding(src_positions))\n",
        "        )\n",
        "        embed_trg = self.dropout(\n",
        "            (self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\n",
        "        )\n",
        "\n",
        "        src_padding_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(\n",
        "            self.device\n",
        "        )\n",
        "\n",
        "        out = self.transformer(\n",
        "            embed_src,\n",
        "            embed_trg,\n",
        "            src_key_padding_mask=src_padding_mask,\n",
        "            tgt_mask=trg_mask,\n",
        "        )\n",
        "        out = self.fc_out(out)\n",
        "        return out\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2gGlhCrRwgH"
      },
      "source": [
        "from utils import translate_sentence\n",
        "from utils import bleu\n",
        "from utils import translate_sentence_with_values\n",
        "from utils import save_checkpoint"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKxLFrY8RI8Q"
      },
      "source": [
        "# We're ready to define everything we need for training our Seq2Seq model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "load_model = True\n",
        "save_model = True\n",
        "\n",
        "# Training hyperparameters\n",
        "num_epochs = 5\n",
        "learning_rate = 3e-4\n",
        "batch_size = 32\n",
        "\n",
        "# Model hyperparameters\n",
        "src_vocab_size = len(Input.vocab)\n",
        "trg_vocab_size = len(Output.vocab)\n",
        "embedding_size = 512\n",
        "num_heads = 8\n",
        "num_encoder_layers = 3\n",
        "num_decoder_layers = 3\n",
        "dropout = 0.10\n",
        "max_len = 100\n",
        "forward_expansion = 4\n",
        "src_pad_idx = Input.vocab.stoi[\"<pad>\"]\n",
        "\n",
        "# Tensorboard to get nice loss plot\n",
        "writer = SummaryWriter(\"runs/loss_plot\")\n",
        "step = 0"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOxVHWvWSPye"
      },
      "source": [
        "# Create our iterators using BucketIterator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDu1vQwYRI4C"
      },
      "source": [
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train_data, valid_data, []), batch_size = batch_size, \n",
        "                                                                sort_key = lambda x: len(x.Input),\n",
        "                                                                sort_within_batch=True, device = device)\n",
        "\n",
        "model = Transformer(\n",
        "    embedding_size,\n",
        "    src_vocab_size,\n",
        "    trg_vocab_size,\n",
        "    src_pad_idx,\n",
        "    num_heads,\n",
        "    num_encoder_layers,\n",
        "    num_decoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_len,\n",
        "    device,\n",
        ").to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mlv_tulSYL6"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWBEf9gtRIwy"
      },
      "source": [
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, factor=0.1, patience=10, verbose=True\n",
        ")\n",
        "\n",
        "pad_idx = Input.vocab.stoi[\"<pad>\"]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "\n",
        "sentence = \"Build a container with width 33 and height 44\""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxlyOhRtRIPd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "3dfa842c-6210-41ac-f61f-0d3619a35457"
      },
      "source": [
        "num_epochs = 15\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
        "\n",
        "    if save_model:\n",
        "        checkpoint = {\n",
        "            \"state_dict\": model.state_dict(),\n",
        "            \"optimizer\": optimizer.state_dict(),\n",
        "        }\n",
        "        save_checkpoint(checkpoint)\n",
        "\n",
        "    model.eval()\n",
        "    translated_sentence = translate_sentence_with_values(\n",
        "        model, sentence, Input, Output, device, max_length=50\n",
        "    )\n",
        "\n",
        "    print(f\"Translated sentence: \\n {translated_sentence}\")\n",
        "    model.train()\n",
        "    losses = []\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_iterator):\n",
        "        # Get input and targets and get to cuda\n",
        "        inp_data = batch.Input.to(device)\n",
        "        target = batch.Output.to(device)\n",
        "\n",
        "        # Forward prop\n",
        "        output = model(inp_data, target[:-1, :])\n",
        "        \n",
        "        output = output.reshape(-1, output.shape[2])\n",
        "        target = target[1:].reshape(-1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # Back prop\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "\n",
        "        optimizer.step()\n",
        "        \n",
        "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
        "        step += 1\n",
        "\n",
        "    mean_loss = sum(losses) / len(losses)\n",
        "    scheduler.step(mean_loss)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 0 / 15]\n",
            "=> Saving checkpoint\n",
            "Translated sentence: \n",
            " None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-decf4eb34ebc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mmean_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX4ygz8CRIgV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8bb879d-123a-41ec-ee47-d2fc5c693785"
      },
      "source": [
        "score = bleu(test_data[1:500], model, Input, Output, device)\n",
        "print(f\"Bleu score {score * 100:.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bleu score 99.06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxoWtmYiuxX4",
        "outputId": "e5fad207-a4f6-4c3f-c703-d0334d7504d5"
      },
      "source": [
        "import re\n",
        "model.eval()\n",
        "asks = [\n",
        "        \"create a box with color Color.red\",\n",
        "        'create a text with \"this is my text inside row\"'\n",
        "        \"draw a box with width 24\",\n",
        "        \"build a box with width 22 and height 80\",\n",
        "        \"build a box with height 44 and width 12\",\n",
        "        'write a text with \"This is me\" with color Color.red',\n",
        "        'build a text with \"Hello\" and textSize 22',\n",
        "        \"build a box with width value inside center\",\n",
        "]\n",
        "\n",
        "for it in asks:\n",
        "  dot_values = []\n",
        "  for dot_val in re.findall(\"\\.[a-z]+\", it):\n",
        "    dot_values.append(dot_val)\n",
        "    it = it.replace(dot_val, \".value\")\n",
        "  str_values = []\n",
        "\n",
        "  pattern = r'\"([A-Za-z0-9 ]*)\"'\n",
        "  for str_val in re.findall(pattern, it):\n",
        "    str_values.append(str_val)\n",
        "    it = it.replace(str_val, \"value\")\n",
        "\n",
        "  code = ''.join(translate_sentence(model, it, Input, Output, device, max_length=50)).replace('<eos>','').replace('utf-8','')\n",
        "  # print(code)\n",
        "  for idx, dot_val in enumerate(re.findall(\".value\", code)):\n",
        "    if len(dot_values) > idx:\n",
        "      code = code.replace(\".value\", dot_values[idx])\n",
        "  \n",
        "  for idx, str_val in enumerate(re.findall(\"value\", code)):\n",
        "    if len(str_values) > idx:\n",
        "      code = code.replace(\"value\", f'\"{str_values[idx]}\"')\n",
        "\n",
        "  print(code)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Container(color:Colors.red)\n",
            "Container(margin:EdgeInsets.all(\"this is my text inside row\"),margin:EdgeInsets.all(\"this is my text inside row\"))\n",
            "Container(width:value,height:value)\n",
            "Container(height:value,width:value)\n",
            "Container(child:[CustomText(\"This is me\",fontColor:Colors.red)],)\n",
            "CustomText(fontSize:\"Hello\",\"Hello\")\n",
            "Center(child:Container(width:value))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LV2icql7hkC"
      },
      "source": [
        "# !cp -i /content/English-to-Flutter-widget/my_checkpoint.pth.tar /content/drive/MyDrive/FlutterGenerator"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}