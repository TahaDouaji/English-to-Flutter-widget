{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of seq2seq_transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCEmvQRNy08n"
      },
      "source": [
        "# Transformer model for converting English sentences into Flutter UI widgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL8eiwoIKHAY"
      },
      "source": [
        "In these lines of code, we'll train **Seq2seq Transformer** model to convert natural English sentences into Flutter UI widget code.\n",
        "\n",
        "Our generated dataset has around 175000 English sentences and around 175000 Flutter widget code\n",
        "\n",
        "The goal of this experiment is totally for research purposes, We're not going to support all Flutter widgets for the current phase and also we are using some custom Widget instead of the regular widget to make things easier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaquklxUshV7"
      },
      "source": [
        "!git clone https://github.com/TahaDouaji/English-to-Flutter-widget.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6ob-B1Bsls7"
      },
      "source": [
        "%cd English-to-Flutter-widget/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlDML1sGRA0H"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import spacy\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchtext.legacy.datasets import Multi30k\n",
        "from torchtext.legacy.data import Field, BucketIterator\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfCHrN2ULCkx"
      },
      "source": [
        "# Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPXXqBITuoqp"
      },
      "source": [
        "import json\n",
        "dataset = []\n",
        "with open(\"data_set.json\", 'r') as file:\n",
        "    data_json = file.read()\n",
        "\n",
        "    array_of_obj = json.loads(data_json)\n",
        "    for it in array_of_obj:\n",
        "        dataset.append(it)\n",
        "\n",
        "print(len(dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QS_ojMVutuO"
      },
      "source": [
        "from random import shuffle\n",
        "shuffle(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERkU1ab_LWBH"
      },
      "source": [
        "dataset[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imf9rcPsMbMW"
      },
      "source": [
        "# Tokenizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPn_KZY-MdbL"
      },
      "source": [
        "For English sentences, we're going to use Spacy as our input Tokenizer\n",
        "For the output Tokenizer, we'll build our own custom tokenizer. We didn't find a suitable tokenizer for Dart/Flutter so we'll be using Python's default[tokenize](https://docs.python.org/3/library/tokenize.html) for now and it will be changed later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkjlW18whxs9"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtQJ0XqCX7_D"
      },
      "source": [
        "from tokenize import tokenize, untokenize\n",
        "import io\n",
        "\n",
        "\n",
        "def tokenize_flutter_code(str_code):\n",
        "    fluttere_tokens = list(tokenize(io.BytesIO(str_code.encode('utf-8')).readline))\n",
        "    return [it.string for it in fluttere_tokens if len(it.string) > 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqOMP67SQUW4"
      },
      "source": [
        "tokenize_flutter_code(\"Container(color:Color.red)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqUgeel-wzNu"
      },
      "source": [
        "from torchtext.legacy import data\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wl5-dG4thb-"
      },
      "source": [
        "Input = Field(tokenize='spacy',\n",
        "            init_token='<sos>', \n",
        "            eos_token='<eos>', \n",
        "            lower=True)\n",
        "\n",
        "Output = Field(tokenize = tokenize_flutter_code,\n",
        "                      init_token='<sos>', \n",
        "                    eos_token='<eos>', \n",
        "                    lower=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR6Idc0fuZgV"
      },
      "source": [
        "fields = [('Input', Input),('Output', Output)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usWMgI3sRmvt"
      },
      "source": [
        "# Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVzqy5o3u95Z"
      },
      "source": [
        "dataset_df = pd.DataFrame(dataset)\n",
        "\n",
        "\n",
        "np.random.seed(0)\n",
        "msk = np.random.rand(len(dataset_df)) < 0.85\n",
        "\n",
        "\n",
        "train_df = dataset_df[msk]\n",
        "val_df = dataset_df[~msk]\n",
        "\n",
        "val_msk = np.random.rand(len(pd.DataFrame(train_df))) < 0.85\n",
        "test_df = train_df[~val_msk]\n",
        "train_df = train_df[val_msk]\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "train_example = []\n",
        "val_example = []\n",
        "test_example = []\n",
        "\n",
        "for i in range(train_df.shape[0]):\n",
        "    try:\n",
        "        ex = data.Example.fromlist([train_df.sentence[i], train_df.widget[i]], fields)\n",
        "        train_example.append(ex)\n",
        "    except Exception as e:\n",
        "        pass\n",
        "\n",
        "for i in range(val_df.shape[0]):\n",
        "    try:\n",
        "        ex = data.Example.fromlist([val_df.sentence[i], val_df.widget[i]], fields)\n",
        "        val_example.append(ex)\n",
        "    except:\n",
        "        pass  \n",
        "\n",
        "for i in range(test_df.shape[0]):\n",
        "    try:\n",
        "        ex = data.Example.fromlist([test_df.sentence[i], test_df.widget[i]], fields)\n",
        "        test_example.append(ex)\n",
        "    except:\n",
        "        pass       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY5aBm0FIDU9"
      },
      "source": [
        "len(train_example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLzv4ZoiRu9X"
      },
      "source": [
        "# Creating vocabulary using torchtext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzspadWERec_"
      },
      "source": [
        "train_data = data.Dataset(train_example, fields)\n",
        "valid_data =  data.Dataset(val_example, fields)\n",
        "test_data =  data.Dataset(test_example, fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zPabvACzF-R"
      },
      "source": [
        "Input.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "Output.build_vocab(train_data, max_size=10000, min_freq=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB39Q9iSR8Cf"
      },
      "source": [
        "# Transformer class model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9VVFtIjRI_I"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size,\n",
        "        src_vocab_size,\n",
        "        trg_vocab_size,\n",
        "        src_pad_idx,\n",
        "        num_heads,\n",
        "        num_encoder_layers,\n",
        "        num_decoder_layers,\n",
        "        forward_expansion,\n",
        "        dropout,\n",
        "        max_len,\n",
        "        device,\n",
        "    ):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
        "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
        "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
        "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n",
        "\n",
        "        self.device = device\n",
        "        self.transformer = nn.Transformer(\n",
        "            embedding_size,\n",
        "            num_heads,\n",
        "            num_encoder_layers,\n",
        "            num_decoder_layers,\n",
        "            forward_expansion,\n",
        "            dropout,\n",
        "        )\n",
        "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
        "\n",
        "        # (N, src_len)\n",
        "        return src_mask.to(self.device)\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        src_seq_length, N = src.shape\n",
        "        trg_seq_length, N = trg.shape\n",
        "\n",
        "        src_positions = (\n",
        "            torch.arange(0, src_seq_length)\n",
        "            .unsqueeze(1)\n",
        "            .expand(src_seq_length, N)\n",
        "            .to(self.device)\n",
        "        )\n",
        "\n",
        "        trg_positions = (\n",
        "            torch.arange(0, trg_seq_length)\n",
        "            .unsqueeze(1)\n",
        "            .expand(trg_seq_length, N)\n",
        "            .to(self.device)\n",
        "        )\n",
        "\n",
        "        embed_src = self.dropout(\n",
        "            (self.src_word_embedding(src) + self.src_position_embedding(src_positions))\n",
        "        )\n",
        "        embed_trg = self.dropout(\n",
        "            (self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\n",
        "        )\n",
        "\n",
        "        src_padding_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(\n",
        "            self.device\n",
        "        )\n",
        "\n",
        "        out = self.transformer(\n",
        "            embed_src,\n",
        "            embed_trg,\n",
        "            src_key_padding_mask=src_padding_mask,\n",
        "            tgt_mask=trg_mask,\n",
        "        )\n",
        "        out = self.fc_out(out)\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2gGlhCrRwgH"
      },
      "source": [
        "from utils import translate_sentence\n",
        "from utils import bleu\n",
        "from utils import translate_sentence_with_values\n",
        "from utils import save_checkpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKxLFrY8RI8Q"
      },
      "source": [
        "# We're ready to define everything we need for training our Seq2Seq model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "load_model = True\n",
        "save_model = True\n",
        "\n",
        "# Training hyperparameters\n",
        "num_epochs = 5\n",
        "learning_rate = 3e-4\n",
        "batch_size = 32\n",
        "\n",
        "# Model hyperparameters\n",
        "src_vocab_size = len(Input.vocab)\n",
        "trg_vocab_size = len(Output.vocab)\n",
        "embedding_size = 512\n",
        "num_heads = 8\n",
        "num_encoder_layers = 3\n",
        "num_decoder_layers = 3\n",
        "dropout = 0.10\n",
        "max_len = 100\n",
        "forward_expansion = 4\n",
        "src_pad_idx = Input.vocab.stoi[\"<pad>\"]\n",
        "\n",
        "# Tensorboard to get nice loss plot\n",
        "writer = SummaryWriter(\"runs/loss_plot\")\n",
        "step = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOxVHWvWSPye"
      },
      "source": [
        "# Create our iterators using BucketIterator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDu1vQwYRI4C"
      },
      "source": [
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train_data, valid_data, []), batch_size = batch_size, \n",
        "                                                                sort_key = lambda x: len(x.Input),\n",
        "                                                                sort_within_batch=True, device = device)\n",
        "\n",
        "model = Transformer(\n",
        "    embedding_size,\n",
        "    src_vocab_size,\n",
        "    trg_vocab_size,\n",
        "    src_pad_idx,\n",
        "    num_heads,\n",
        "    num_encoder_layers,\n",
        "    num_decoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_len,\n",
        "    device,\n",
        ").to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mlv_tulSYL6"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWBEf9gtRIwy"
      },
      "source": [
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, factor=0.1, patience=10, verbose=True\n",
        ")\n",
        "\n",
        "pad_idx = Input.vocab.stoi[\"<pad>\"]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "\n",
        "sentence = \"Build a container with width 33 and height 44\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxlyOhRtRIPd"
      },
      "source": [
        "num_epochs = 15\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
        "\n",
        "    if save_model:\n",
        "        checkpoint = {\n",
        "            \"state_dict\": model.state_dict(),\n",
        "            \"optimizer\": optimizer.state_dict(),\n",
        "        }\n",
        "        save_checkpoint(checkpoint)\n",
        "\n",
        "    model.eval()\n",
        "    translated_sentence = translate_sentence_with_values(\n",
        "        model, sentence, Input, Output, device, max_length=50\n",
        "    )\n",
        "\n",
        "    print(f\"Translated sentence: \\n {translated_sentence}\")\n",
        "    model.train()\n",
        "    losses = []\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_iterator):\n",
        "        # Get input and targets and get to cuda\n",
        "        inp_data = batch.Input.to(device)\n",
        "        target = batch.Output.to(device)\n",
        "\n",
        "        # Forward prop\n",
        "        output = model(inp_data, target[:-1, :])\n",
        "        \n",
        "        output = output.reshape(-1, output.shape[2])\n",
        "        target = target[1:].reshape(-1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # Back prop\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "\n",
        "        optimizer.step()\n",
        "        \n",
        "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
        "        step += 1\n",
        "\n",
        "    mean_loss = sum(losses) / len(losses)\n",
        "    scheduler.step(mean_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX4ygz8CRIgV"
      },
      "source": [
        "score = bleu(test_data[1:500], model, Input, Output, device)\n",
        "print(f\"Bleu score {score * 100:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}